# Cryptostore sample config file

# Redis or Kafka are required. They are used to batch updates from cryptofeed and the storage medium of choice
#
# del_after_read: (redis only) toggles the removal of data from redis after it has been processed with cryptostore.
# retention_time: (redis only) if data removal is enabled (via del_after_read) will allow retention of data in redis for N seconds.
# socket: (redis only) allows redis connections via a unix domain socket
# start_flush: toggles if redis/kafka should be flushed at the start. Primarily for debugging, it will flush ALL of redis/kafka
cache: redis

redis:
    ip: '127.0.0.1'
    port: 6379
    socket: null
    del_after_read: true
    retention_time: null
    start_flush: true

# Data sources and data types configured under exchanges. Exchange names follow the naming scheme in cryptofeed (they
# must be capitalized) and only exchanges supported by cryptofeed are supported.
# data types follow cryptofeed definitions, see defines.py in cryptofeed for more details, common ones are
# trades, l2_book, l3_book, funding, ticker, and open_interest
# Trading pairs for all exchanges (except BitMEX) follow the currency-quote format
#
# max_depth controls the size of the book to return. The top N levels will be returned, only when those N levels
# have changed.
# book_delta enables book deltas (snapshot, then only deltas are delivered). Snapshops are delivered
# every book_interval updates. book_interval defaults to 1000 if not specified
#
# Retries are the number of times the connection to the exchange will be retried before exiting. -1 is infinity.
# Using a retry of -1 with a bug in your config can lead to bans by exchanges
#
# Channel timeouts are channel specific and control how long a channel can go with no messages before declaring the connection
# dead. Cryptofeed will restart the connection if no message is received in this time period. Default is 120 seconds. -1 means no timeout.

exchanges:
    BINANCE:
        retries: 4
        trades: [BTC-USDT, ETH-USDT]

# Parquet specific options. Parquet will default to storing the data on disk unless these are specified
parquet:
    # if storing the data to an external source (like S3) toggle this to enable the removal of the local file after
    # writing to external store
    del_file: true
    # File name format, as a list of arguments. Default is <exchange>-<data_type>-<pair>-<timestamp>.parquet, which would be exchange, data_type, pair, timestamp
    # Can specify any combination exchange, data_type, pair, and timestamp
    # timestamp MUST be present.
    # examples:
    #    pair,timestamp
    #    timestamp
    #    timestamp,exchange
    #    etc
    file_format: [exchange, pair, data_type, timestamp]
    # Path controls where the file is written (if not using S3/GC) If null, will write to CWD. Must be absolute path
    path: '/home/pierre/Documents/code/cs_draft/data_test'

    GD:
        # path to service account key (compulsory - absolute path)
        # prefix: name of existing folder in Google Drive for which the service account has writer rights.
        service_account: '/home/pierre/Documents/code/cs_draft/cryptostore-storage3.json'
        prefix: 'Cryptostore'


# Data batching window, in seconds, or optionally a time interval: M(inutely), H(ourly), D(aily).
# These intervals will require that you have enough memory available to redis (and python) to hold this amount of data.
# String intervals can be combined with numbers, eg 2H is 2 hours, 5M is 5 minutes, etc.
storage_interval: 60


# Cryptostore Plugin Interface
#plugins:
#    backfill:
        # The import path, and class name
        # from cryptostore.plugin.backfill import Backfill
#        module: [cryptostore.plugin.backfill, Backfill]
        # Config path, config can be added to this file, or in a separate config
        # backfill does not use a dynamic config, so its fine to put its config here
#        config: config.yaml

# If configured, backfill will run in a separate process and
# backfill trade data from earliest data (in storage) up to `start` (inclusive).
#backfill:
#    COINBASE:
#        BTC-USD:
#            start: '2017-01-01'
